# ==============================================================================
# Copyright (C) 2021 Evil0ctal
#
# This file is part of the Douyin_TikTok_Download_API project.
#
# This project is licensed under the Apache License 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
# ã€€ã€€ã€€ã€€ ã€€ã€€  ï¼¿ï¼¿
# ã€€ã€€ã€€ ã€€ã€€ ï¼ï¼ã€€ã€€ãƒ•
# ã€€ã€€ã€€ ã€€ã€€| ã€€_ã€€ _ l
# ã€€ ã€€ã€€ ã€€ï¼` ãƒŸï¼¿xãƒ
# ã€€ã€€ ã€€ /ã€€ã€€ã€€ ã€€ |       Feed me Stars â­ ï¸
# ã€€ã€€ã€€ /ã€€ ãƒ½ã€€ã€€ ï¾‰
# ã€€ ã€€ â”‚ã€€ã€€|ã€€|ã€€|
# ã€€ï¼ï¿£|ã€€ã€€ |ã€€|ã€€|
# ã€€| (ï¿£ãƒ½ï¼¿_ãƒ½_)__)
# ã€€ï¼¼äºŒã¤
# ==============================================================================
#
# Contributor Link:
# - https://github.com/Evil0ctal
# - https://github.com/Johnserf-Seed
#
# ==============================================================================


import asyncio  # å¼‚æ­¥I/O
import os  # ç³»ç»Ÿæ“ä½œ
import time  # æ—¶é—´æ“ä½œ
from urllib.parse import urlencode, quote  # URLç¼–ç 
import yaml  # é…ç½®æ–‡ä»¶

# åŸºç¡€çˆ¬è™«å®¢æˆ·ç«¯å’ŒæŠ–éŸ³APIç«¯ç‚¹
from crawlers.base_crawler import BaseCrawler
from crawlers.douyin.web.endpoints import DouyinAPIEndpoints
# æŠ–éŸ³æ¥å£æ•°æ®è¯·æ±‚æ¨¡å‹
from crawlers.douyin.web.models import (
    BaseRequestModel, LiveRoomRanking, PostComments,
    PostCommentsReply, PostDetail,
    UserProfile, UserCollection, UserLike, UserLive,
    UserLive2, UserMix, UserPost
)
# æŠ–éŸ³åº”ç”¨çš„å·¥å…·ç±»
from crawlers.douyin.web.utils import (AwemeIdFetcher,  # Aweme IDè·å–
                                       BogusManager,  # XBogusç®¡ç†
                                       SecUserIdFetcher,  # å®‰å…¨ç”¨æˆ·IDè·å–
                                       TokenManager,  # ä»¤ç‰Œç®¡ç†
                                       VerifyFpManager,  # éªŒè¯ç®¡ç†
                                       WebCastIdFetcher,  # ç›´æ’­IDè·å–
                                       extract_valid_urls  # URLæå–
                                       )

# é…ç½®æ–‡ä»¶è·¯å¾„
path = os.path.abspath(os.path.dirname(__file__))

# è¯»å–é…ç½®æ–‡ä»¶
with open(f"{path}/config.yaml", "r", encoding="utf-8") as f:
    config = yaml.safe_load(f)


class DouyinWebCrawler:

    # ä»é…ç½®æ–‡ä»¶ä¸­è·å–æŠ–éŸ³çš„è¯·æ±‚å¤´
    async def get_douyin_headers(self):
        douyin_config = config["TokenManager"]["douyin"]
        kwargs = {
            "headers": {
                "Accept-Language": douyin_config["headers"]["Accept-Language"],
                "User-Agent": douyin_config["headers"]["User-Agent"],
                "Referer": douyin_config["headers"]["Referer"],
                "Cookie": douyin_config["headers"]["Cookie"],
            },
            "proxies": {"http://": douyin_config["proxies"]["http"], "https://": douyin_config["proxies"]["https"]},
        }
        return kwargs

    "-------------------------------------------------------handleræ¥å£åˆ—è¡¨-------------------------------------------------------"

    # è·å–å•ä¸ªä½œå“æ•°æ®
    async def fetch_one_video(self, aweme_id: str):
        # è·å–æŠ–éŸ³çš„å®æ—¶Cookie
        kwargs = await self.get_douyin_headers()
        # åˆ›å»ºä¸€ä¸ªåŸºç¡€çˆ¬è™«
        base_crawler = BaseCrawler(proxies=kwargs["proxies"], crawler_headers=kwargs["headers"])
        async with base_crawler as crawler:
            # åˆ›å»ºä¸€ä¸ªä½œå“è¯¦æƒ…çš„BaseModelå‚æ•°
            params = PostDetail(aweme_id=aweme_id)
            # ç”Ÿæˆä¸€ä¸ªä½œå“è¯¦æƒ…çš„å¸¦æœ‰åŠ å¯†å‚æ•°çš„Endpoint
            # 2024å¹´6æœˆ12æ—¥22:41:44 ç”±äºXBogusåŠ å¯†å·²ç»å¤±æ•ˆï¼Œæ‰€ä»¥ä¸å†ä½¿ç”¨XBogusåŠ å¯†å‚æ•°ï¼Œè½¬ç§»è‡³a_bogusåŠ å¯†å‚æ•°ã€‚
            # endpoint = BogusManager.xb_model_2_endpoint(
            #     DouyinAPIEndpoints.POST_DETAIL, params.dict(), kwargs["headers"]["User-Agent"]
            # )

            # ç”Ÿæˆä¸€ä¸ªä½œå“è¯¦æƒ…çš„å¸¦æœ‰a_bogusåŠ å¯†å‚æ•°çš„Endpoint
            params_dict = params.dict()
            params_dict["msToken"] = ''
            a_bogus = BogusManager.ab_model_2_endpoint(params_dict, kwargs["headers"]["User-Agent"])
            endpoint = f"{DouyinAPIEndpoints.POST_DETAIL}?{urlencode(params_dict)}&a_bogus={a_bogus}"

            response = await crawler.fetch_get_json(endpoint)
        return response

    # è·å–ç”¨æˆ·å‘å¸ƒä½œå“æ•°æ®
    async def fetch_user_post_videos(self, sec_user_id: str, max_cursor: int, count: int):
        kwargs = await self.get_douyin_headers()
        base_crawler = BaseCrawler(proxies=kwargs["proxies"], crawler_headers=kwargs["headers"])
        async with base_crawler as crawler:
            params = UserPost(sec_user_id=sec_user_id, max_cursor=max_cursor, count=count)
            # endpoint = BogusManager.xb_model_2_endpoint(
            #     DouyinAPIEndpoints.USER_POST, params.dict(), kwargs["headers"]["User-Agent"]
            # )
            # response = await crawler.fetch_get_json(endpoint)

            # ç”Ÿæˆä¸€ä¸ªç”¨æˆ·å‘å¸ƒä½œå“æ•°æ®çš„å¸¦æœ‰a_bogusåŠ å¯†å‚æ•°çš„Endpoint
            params_dict = params.dict()
            params_dict["msToken"] = ''
            a_bogus = BogusManager.ab_model_2_endpoint(params_dict, kwargs["headers"]["User-Agent"])
            endpoint = f"{DouyinAPIEndpoints.USER_POST}?{urlencode(params_dict)}&a_bogus={a_bogus}"

            response = await crawler.fetch_get_json(endpoint)
        return response

    # è·å–ç”¨æˆ·å–œæ¬¢ä½œå“æ•°æ®
    async def fetch_user_like_videos(self, sec_user_id: str, max_cursor: int, count: int):
        kwargs = await self.get_douyin_headers()
        base_crawler = BaseCrawler(proxies=kwargs["proxies"], crawler_headers=kwargs["headers"])
        async with base_crawler as crawler:
            params = UserLike(sec_user_id=sec_user_id, max_cursor=max_cursor, count=count)
            # endpoint = BogusManager.xb_model_2_endpoint(
            #     DouyinAPIEndpoints.USER_FAVORITE_A, params.dict(), kwargs["headers"]["User-Agent"]
            # )
            # response = await crawler.fetch_get_json(endpoint)

            params_dict = params.dict()
            params_dict["msToken"] = ''
            a_bogus = BogusManager.ab_model_2_endpoint(params_dict, kwargs["headers"]["User-Agent"])
            endpoint = f"{DouyinAPIEndpoints.USER_FAVORITE_A}?{urlencode(params_dict)}&a_bogus={a_bogus}"

            response = await crawler.fetch_get_json(endpoint)
        return response

    # è·å–ç”¨æˆ·æ”¶è—ä½œå“æ•°æ®ï¼ˆç”¨æˆ·æä¾›è‡ªå·±çš„Cookieï¼‰
    async def fetch_user_collection_videos(self, cookie: str, cursor: int = 0, count: int = 20):
        kwargs = await self.get_douyin_headers()
        kwargs["headers"]["Cookie"] = cookie
        base_crawler = BaseCrawler(proxies=kwargs["proxies"], crawler_headers=kwargs["headers"])
        async with base_crawler as crawler:
            params = UserCollection(cursor=cursor, count=count)
            endpoint = BogusManager.xb_model_2_endpoint(
                DouyinAPIEndpoints.USER_COLLECTION, params.dict(), kwargs["headers"]["User-Agent"]
            )
            response = await crawler.fetch_post_json(endpoint)
        return response

    # è·å–ç”¨æˆ·åˆè¾‘ä½œå“æ•°æ®
    async def fetch_user_mix_videos(self, mix_id: str, cursor: int = 0, count: int = 20):
        kwargs = await self.get_douyin_headers()
        base_crawler = BaseCrawler(proxies=kwargs["proxies"], crawler_headers=kwargs["headers"])
        async with base_crawler as crawler:
            params = UserMix(mix_id=mix_id, cursor=cursor, count=count)
            endpoint = BogusManager.xb_model_2_endpoint(
                DouyinAPIEndpoints.MIX_AWEME, params.dict(), kwargs["headers"]["User-Agent"]
            )
            response = await crawler.fetch_get_json(endpoint)
        return response

    # è·å–ç”¨æˆ·ç›´æ’­æµæ•°æ®
    async def fetch_user_live_videos(self, webcast_id: str, room_id_str=""):
        kwargs = await self.get_douyin_headers()
        base_crawler = BaseCrawler(proxies=kwargs["proxies"], crawler_headers=kwargs["headers"])
        async with base_crawler as crawler:
            params = UserLive(web_rid=webcast_id, room_id_str=room_id_str)
            endpoint = BogusManager.xb_model_2_endpoint(
                DouyinAPIEndpoints.LIVE_INFO, params.dict(), kwargs["headers"]["User-Agent"]
            )
            response = await crawler.fetch_get_json(endpoint)
        return response

    # è·å–æŒ‡å®šç”¨æˆ·çš„ç›´æ’­æµæ•°æ®
    async def fetch_user_live_videos_by_room_id(self, room_id: str):
        kwargs = await self.get_douyin_headers()
        base_crawler = BaseCrawler(proxies=kwargs["proxies"], crawler_headers=kwargs["headers"])
        async with base_crawler as crawler:
            params = UserLive2(room_id=room_id)
            endpoint = BogusManager.xb_model_2_endpoint(
                DouyinAPIEndpoints.LIVE_INFO_ROOM_ID, params.dict(), kwargs["headers"]["User-Agent"]
            )
            response = await crawler.fetch_get_json(endpoint)
        return response

    # è·å–ç›´æ’­é—´é€ç¤¼ç”¨æˆ·æ’è¡Œæ¦œ
    async def fetch_live_gift_ranking(self, room_id: str, rank_type: int = 30):
        kwargs = await self.get_douyin_headers()
        base_crawler = BaseCrawler(proxies=kwargs["proxies"], crawler_headers=kwargs["headers"])
        async with base_crawler as crawler:
            params = LiveRoomRanking(room_id=room_id, rank_type=rank_type)
            endpoint = BogusManager.xb_model_2_endpoint(
                DouyinAPIEndpoints.LIVE_GIFT_RANK, params.dict(), kwargs["headers"]["User-Agent"]
            )
            response = await crawler.fetch_get_json(endpoint)
        return response

    # è·å–æŒ‡å®šç”¨æˆ·çš„ä¿¡æ¯
    async def handler_user_profile(self, sec_user_id: str):
        kwargs = await self.get_douyin_headers()
        base_crawler = BaseCrawler(proxies=kwargs["proxies"], crawler_headers=kwargs["headers"])
        async with base_crawler as crawler:
            params = UserProfile(sec_user_id=sec_user_id)
            endpoint = BogusManager.xb_model_2_endpoint(
                DouyinAPIEndpoints.USER_DETAIL, params.dict(), kwargs["headers"]["User-Agent"]
            )
            response = await crawler.fetch_get_json(endpoint)
        return response

    # è·å–æŒ‡å®šè§†é¢‘çš„è¯„è®ºæ•°æ®
    async def fetch_video_comments(self, aweme_id: str, cursor: int = 0, count: int = 20):
        kwargs = await self.get_douyin_headers()
        base_crawler = BaseCrawler(proxies=kwargs["proxies"], crawler_headers=kwargs["headers"])
        async with base_crawler as crawler:
            params = PostComments(aweme_id=aweme_id, cursor=cursor, count=count)
            endpoint = BogusManager.xb_model_2_endpoint(
                DouyinAPIEndpoints.POST_COMMENT, params.dict(), kwargs["headers"]["User-Agent"]
            )
            response = await crawler.fetch_get_json(endpoint)
        return response

    # è·å–æŒ‡å®šè§†é¢‘çš„è¯„è®ºå›å¤æ•°æ®
    async def fetch_video_comments_reply(self, item_id: str, comment_id: str, cursor: int = 0, count: int = 20):
        kwargs = await self.get_douyin_headers()
        base_crawler = BaseCrawler(proxies=kwargs["proxies"], crawler_headers=kwargs["headers"])
        async with base_crawler as crawler:
            params = PostCommentsReply(item_id=item_id, comment_id=comment_id, cursor=cursor, count=count)
            endpoint = BogusManager.xb_model_2_endpoint(
                DouyinAPIEndpoints.POST_COMMENT_REPLY, params.dict(), kwargs["headers"]["User-Agent"]
            )
            response = await crawler.fetch_get_json(endpoint)
        return response

    # è·å–æŠ–éŸ³çƒ­æ¦œæ•°æ®
    async def fetch_hot_search_result(self):
        kwargs = await self.get_douyin_headers()
        base_crawler = BaseCrawler(proxies=kwargs["proxies"], crawler_headers=kwargs["headers"])
        async with base_crawler as crawler:
            params = BaseRequestModel()
            endpoint = BogusManager.xb_model_2_endpoint(
                DouyinAPIEndpoints.DOUYIN_HOT_SEARCH, params.dict(), kwargs["headers"]["User-Agent"]
            )
            response = await crawler.fetch_get_json(endpoint)
        return response

    "-------------------------------------------------------utilsæ¥å£åˆ—è¡¨-------------------------------------------------------"

    # ç”ŸæˆçœŸå®msToken
    async def gen_real_msToken(self, ):
        result = {
            "msToken": TokenManager().gen_real_msToken()
        }
        return result

    # ç”Ÿæˆttwid
    async def gen_ttwid(self, ):
        result = {
            "ttwid": TokenManager().gen_ttwid()
        }
        return result

    # ç”Ÿæˆverify_fp
    async def gen_verify_fp(self, ):
        result = {
            "verify_fp": VerifyFpManager.gen_verify_fp()
        }
        return result

    # ç”Ÿæˆs_v_web_id
    async def gen_s_v_web_id(self, ):
        result = {
            "s_v_web_id": VerifyFpManager.gen_s_v_web_id()
        }
        return result

    # ä½¿ç”¨æ¥å£åœ°å€ç”ŸæˆXbå‚æ•°
    async def get_x_bogus(self, url: str, user_agent: str):
        url = BogusManager.xb_str_2_endpoint(url, user_agent)
        result = {
            "url": url,
            "x_bogus": url.split("&X-Bogus=")[1],
            "user_agent": user_agent
        }
        return result

    # ä½¿ç”¨æ¥å£åœ°å€ç”ŸæˆAbå‚æ•°
    async def get_a_bogus(self, url: str, user_agent: str):
        endpoint = url.split("?")[0]
        # å°†URLå‚æ•°è½¬æ¢ä¸ºdict
        params = dict([i.split("=") for i in url.split("?")[1].split("&")])
        # å»é™¤URLä¸­çš„msTokenå‚æ•°
        params["msToken"] = ""
        a_bogus = BogusManager.ab_model_2_endpoint(params, user_agent)
        result = {
            "url": f"{endpoint}?{urlencode(params)}&a_bogus={a_bogus}",
            "a_bogus": a_bogus,
            "user_agent": user_agent
        }
        return result

    # æå–å•ä¸ªç”¨æˆ·id
    async def get_sec_user_id(self, url: str):
        return await SecUserIdFetcher.get_sec_user_id(url)

    # æå–åˆ—è¡¨ç”¨æˆ·id
    async def get_all_sec_user_id(self, urls: list):
        # æå–æœ‰æ•ˆURL
        urls = extract_valid_urls(urls)

        # å¯¹äºURLåˆ—è¡¨
        return await SecUserIdFetcher.get_all_sec_user_id(urls)

    # æå–å•ä¸ªä½œå“id
    async def get_aweme_id(self, url: str):
        return await AwemeIdFetcher.get_aweme_id(url)

    # æå–åˆ—è¡¨ä½œå“id
    async def get_all_aweme_id(self, urls: list):
        # æå–æœ‰æ•ˆURL
        urls = extract_valid_urls(urls)

        # å¯¹äºURLåˆ—è¡¨
        return await AwemeIdFetcher.get_all_aweme_id(urls)

    # æå–å•ä¸ªç›´æ’­é—´å·
    async def get_webcast_id(self, url: str):
        return await WebCastIdFetcher.get_webcast_id(url)

    # æå–åˆ—è¡¨ç›´æ’­é—´å·
    async def get_all_webcast_id(self, urls: list):
        # æå–æœ‰æ•ˆURL
        urls = extract_valid_urls(urls)

        # å¯¹äºURLåˆ—è¡¨
        return await WebCastIdFetcher.get_all_webcast_id(urls)

    async def main(self):
        """-------------------------------------------------------handleræ¥å£åˆ—è¡¨-------------------------------------------------------"""

        # è·å–å•ä¸€è§†é¢‘ä¿¡æ¯
        # aweme_id = "7372484719365098803"
        # result = await self.fetch_one_video(aweme_id)
        # print(result)

        # è·å–ç”¨æˆ·å‘å¸ƒä½œå“æ•°æ®
        # sec_user_id = "MS4wLjABAAAANXSltcLCzDGmdNFI2Q_QixVTr67NiYzjKOIP5s03CAE"
        # max_cursor = 0
        # count = 10
        # result = await self.fetch_user_post_videos(sec_user_id, max_cursor, count)
        # print(result)

        # è·å–ç”¨æˆ·å–œæ¬¢ä½œå“æ•°æ®
        # sec_user_id = "MS4wLjABAAAAW9FWcqS7RdQAWPd2AA5fL_ilmqsIFUCQ_Iym6Yh9_cUa6ZRqVLjVQSUjlHrfXY1Y"
        # max_cursor = 0
        # count = 10
        # result = await self.fetch_user_like_videos(sec_user_id, max_cursor, count)
        # print(result)

        # è·å–ç”¨æˆ·æ”¶è—ä½œå“æ•°æ®ï¼ˆç”¨æˆ·æä¾›è‡ªå·±çš„Cookieï¼‰
        # cookie = "å¸¦ä¸Šä½ çš„Cookie/Put your Cookie here"
        # cursor = 0
        # counts = 20
        # result = await self.fetch_user_collection_videos(__cookie, cursor, counts)
        # print(result)

        # è·å–ç”¨æˆ·åˆè¾‘ä½œå“æ•°æ®
        # https://www.douyin.com/collection/7348687990509553679
        # mix_id = "7348687990509553679"
        # cursor = 0
        # counts = 20
        # result = await self.fetch_user_mix_videos(mix_id, cursor, counts)
        # print(result)

        # è·å–ç”¨æˆ·ç›´æ’­æµæ•°æ®
        # https://live.douyin.com/285520721194
        # webcast_id = "285520721194"
        # result = await self.fetch_user_live_videos(webcast_id)
        # print(result)

        # è·å–æŒ‡å®šç”¨æˆ·çš„ç›´æ’­æµæ•°æ®
        # # https://live.douyin.com/7318296342189919011
        # room_id = "7318296342189919011"
        # result = await self.fetch_user_live_videos_by_room_id(room_id)
        # print(result)

        # è·å–ç›´æ’­é—´é€ç¤¼ç”¨æˆ·æ’è¡Œæ¦œ
        # room_id = "7356585666190461731"
        # rank_type = 30
        # result = await self.fetch_live_gift_ranking(room_id, rank_type)
        # print(result)

        # è·å–æŒ‡å®šç”¨æˆ·çš„ä¿¡æ¯
        # sec_user_id = "MS4wLjABAAAAW9FWcqS7RdQAWPd2AA5fL_ilmqsIFUCQ_Iym6Yh9_cUa6ZRqVLjVQSUjlHrfXY1Y"
        # result = await self.handler_user_profile(sec_user_id)
        # print(result)

        # è·å–å•ä¸ªè§†é¢‘è¯„è®ºæ•°æ®
        # aweme_id = "7334525738793618688"
        # result = await self.fetch_video_comments(aweme_id)
        # print(result)

        # è·å–å•ä¸ªè§†é¢‘è¯„è®ºå›å¤æ•°æ®
        # item_id = "7344709764531686690"
        # comment_id = "7346856757471953698"
        # result = await self.fetch_video_comments_reply(item_id, comment_id)
        # print(result)

        # è·å–æŒ‡å®šå…³é”®è¯çš„ç»¼åˆæœç´¢ç»“æœ
        # keyword = "ä¸­åå¨˜"
        # offset = 0
        # count = 20
        # sort_type = "0"
        # publish_time = "0"
        # filter_duration = "0"
        # result = await self.fetch_general_search_result(keyword, offset, count, sort_type, publish_time, filter_duration)
        # print(result)

        # è·å–æŠ–éŸ³çƒ­æ¦œæ•°æ®
        # result = await self.fetch_hot_search_result()
        # print(result)

        """-------------------------------------------------------utilsæ¥å£åˆ—è¡¨-------------------------------------------------------"""

        # è·å–æŠ–éŸ³Webçš„æ¸¸å®¢Cookie
        # user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36"
        # result = await self.fetch_douyin_web_guest_cookie(user_agent)
        # print(result)

        # ç”ŸæˆçœŸå®msToken
        # result = await self.gen_real_msToken()
        # print(result)

        # ç”Ÿæˆttwid
        # result = await self.gen_ttwid()
        # print(result)

        # ç”Ÿæˆverify_fp
        # result = await self.gen_verify_fp()
        # print(result)

        # ç”Ÿæˆs_v_web_id
        # result = await self.gen_s_v_web_id()
        # print(result)

        # ä½¿ç”¨æ¥å£åœ°å€ç”ŸæˆXbå‚æ•°
        # url = "https://www.douyin.com/aweme/v1/web/comment/list/?device_platform=webapp&aid=6383&channel=channel_pc_web&aweme_id=7334525738793618688&cursor=0&count=20&item_type=0&insert_ids=&whale_cut_token=&cut_version=1&rcFT=&pc_client_type=1&version_code=170400&version_name=17.4.0&cookie_enabled=true&screen_width=1344&screen_height=756&browser_language=zh-CN&browser_platform=Win32&browser_name=Firefox&browser_version=124.0&browser_online=true&engine_name=Gecko&engine_version=124.0&os_name=Windows&os_version=10&cpu_core_num=16&device_memory=&platform=PC&webid=7348962975497324070"
        # user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36"
        # result = await self.get_x_bogus(url, user_agent)
        # print(result)

        # æå–å•ä¸ªç”¨æˆ·id
        # raw_url = "https://www.douyin.com/user/MS4wLjABAAAANXSltcLCzDGmdNFI2Q_QixVTr67NiYzjKOIP5s03CAE?vid=7285950278132616463"
        # result = await self.get_sec_user_id(raw_url)
        # print(result)

        # æå–åˆ—è¡¨ç”¨æˆ·id
        # raw_urls = [
        #     "https://www.douyin.com/user/MS4wLjABAAAANXSltcLCzDGmdNFI2Q_QixVTr67NiYzjKOIP5s03CAE?vid=7285950278132616463",
        #     "https://www.douyin.com/user/MS4wLjABAAAAVsneOf144eGDFf8Xp9QNb1VW6ovXnNT5SqJBhJfe8KQBKWKDTWK5Hh-_i9mJzb8C",
        #     "é•¿æŒ‰å¤åˆ¶æ­¤æ¡æ¶ˆæ¯ï¼Œæ‰“å¼€æŠ–éŸ³æœç´¢ï¼ŒæŸ¥çœ‹TAçš„æ›´å¤šä½œå“ã€‚ https://v.douyin.com/idFqvUms/",
        #     "https://v.douyin.com/idFqvUms/",
        # ]
        # result = await self.get_all_sec_user_id(raw_urls)
        # print(result)

        # æå–å•ä¸ªä½œå“id
        # raw_url = "https://www.douyin.com/video/7298145681699622182?previous_page=web_code_link"
        # result = await self.get_aweme_id(raw_url)
        # print(result)

        # æå–åˆ—è¡¨ä½œå“id
        # raw_urls = [
        #     "0.53 02/26 I@v.sE Fus:/ ä½ åˆ«å¤ªå¸…äº†éƒ‘æ¶¦æ³½# ç°åœºç‰ˆlive # éŸ³ä¹èŠ‚ # éƒ‘æ¶¦æ³½  https://v.douyin.com/iRNBho6u/ å¤åˆ¶æ­¤é“¾æ¥ï¼Œæ‰“å¼€DouéŸ³æœç´¢ï¼Œç›´æ¥è§‚çœ‹è§†é¢‘!",
        #     "https://v.douyin.com/iRNBho6u/",
        #     "https://www.iesdouyin.com/share/video/7298145681699622182/?region=CN&mid=7298145762238565171&u_code=l1j9bkbd&did=MS4wLjABAAAAtqpCx0hpOERbdSzQdjRZw-wFPxaqdbAzsKDmbJMUI3KWlMGQHC-n6dXAqa-dM2EP&iid=MS4wLjABAAAANwkJuWIRFOzg5uCpDRpMj4OX-QryoDgn-yYlXQnRwQQ&with_sec_did=1&titleType=title&share_sign=05kGlqGmR4_IwCX.ZGk6xuL0osNA..5ur7b0jbOx6cc-&share_version=170400&ts=1699262937&from_aid=6383&from_ssr=1&from=web_code_link",
        #     "https://www.douyin.com/video/7298145681699622182?previous_page=web_code_link",
        #     "https://www.douyin.com/video/7298145681699622182",
        # ]
        # result = await self.get_all_aweme_id(raw_urls)
        # print(result)

        # æå–å•ä¸ªç›´æ’­é—´å·
        # raw_url = "https://live.douyin.com/775841227732"
        # result = await self.get_webcast_id(raw_url)
        # print(result)

        # æå–åˆ—è¡¨ç›´æ’­é—´å·
        # raw_urls = [
        #     "https://live.douyin.com/775841227732",
        #     "https://live.douyin.com/775841227732?room_id=7318296342189919011&enter_from_merge=web_share_link&enter_method=web_share_link&previous_page=app_code_link",
        #     'https://webcast.amemv.com/douyin/webcast/reflow/7318296342189919011?u_code=l1j9bkbd&did=MS4wLjABAAAAEs86TBQPNwAo-RGrcxWyCdwKhI66AK3Pqf3ieo6HaxI&iid=MS4wLjABAAAA0ptpM-zzoliLEeyvWOCUt-_dQza4uSjlIvbtIazXnCY&with_sec_did=1&use_link_command=1&ecom_share_track_params=&extra_params={"from_request_id":"20231230162057EC005772A8EAA0199906","im_channel_invite_id":"0"}&user_id=3644207898042206&liveId=7318296342189919011&from=share&style=share&enter_method=click_share&roomId=7318296342189919011&activity_info={}',
        #     "6i- Q@x.Sl 03/23 ã€é†’å­8keçš„ç›´æ’­é—´ã€‘  ç‚¹å‡»æ‰“å¼€ğŸ‘‰https://v.douyin.com/i8tBR7hX/  æˆ–é•¿æŒ‰å¤åˆ¶æ­¤æ¡æ¶ˆæ¯ï¼Œæ‰“å¼€æŠ–éŸ³ï¼Œçœ‹TAç›´æ’­",
        #     "https://v.douyin.com/i8tBR7hX/",
        # ]
        # result = await self.get_all_webcast_id(raw_urls)
        # print(result)

        # å ä½
        pass


if __name__ == "__main__":
    # åˆå§‹åŒ–
    DouyinWebCrawler = DouyinWebCrawler()

    # å¼€å§‹æ—¶é—´
    start = time.time()

    asyncio.run(DouyinWebCrawler.main())

    # ç»“æŸæ—¶é—´
    end = time.time()
    print(f"è€—æ—¶ï¼š{end - start}")
